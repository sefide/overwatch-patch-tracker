#!/usr/bin/env python3
"""
ì˜¤ë²„ì›Œì¹˜ íŒ¨ì¹˜ ë…¸íŠ¸ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸
"""

import requests
from bs4 import BeautifulSoup
from datetime import datetime
import re

def scrape_overwatch_patches():
    url = "https://overwatch.blizzard.com/en-us/news/patch-notes/live"
    
    print(f"ğŸ” íŒ¨ì¹˜ ë…¸íŠ¸ í˜ì´ì§€ ì ‘ê·¼ ì¤‘: {url}")
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (compatible; OverwatchPatchTracker/1.0)'
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        print(f"âœ… í˜ì´ì§€ ì ‘ê·¼ ì„±ê³µ (ìƒíƒœ ì½”ë“œ: {response.status_code})")
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ë‚ ì§œ í—¤ë” ì°¾ê¸° (h3 íƒœê·¸)
        date_headers = soup.find_all('h3')
        
        print(f"\nğŸ“… ë°œê²¬ëœ í—¤ë” ìˆ˜: {len(date_headers)}")
        
        patches = []
        
        for header in date_headers[:5]:  # ìµœê·¼ 5ê°œë§Œ
            header_text = header.get_text().strip()
            
            # ë‚ ì§œ íŒ¨í„´ ë§¤ì¹­ (ì˜ˆ: "January 20, 2026")
            date_match = re.search(r'([A-Z][a-z]+)\s+(\d{1,2}),\s+(\d{4})', header_text)
            
            if date_match:
                patch_date = date_match.group(0)
                print(f"\n{'='*60}")
                print(f"ğŸ“Œ íŒ¨ì¹˜ ë‚ ì§œ: {patch_date}")
                
                # ì˜ì›… í—¤ë” ì°¾ê¸° (h5 íƒœê·¸)
                next_element = header.find_next_sibling()
                heroes = []
                
                while next_element and next_element.name != 'h3':
                    if next_element.name == 'h5':
                        hero_name = next_element.get_text().strip()
                        heroes.append(hero_name)
                        
                        # ë³€ê²½ì‚¬í•­ ì°¾ê¸°
                        changes = []
                        change_element = next_element.find_next_sibling()
                        
                        while change_element and change_element.name not in ['h5', 'h3']:
                            if change_element.name == 'ul':
                                for li in change_element.find_all('li'):
                                    change_text = li.get_text().strip()
                                    if change_text:
                                        changes.append(change_text)
                            change_element = change_element.find_next_sibling()
                        
                        if changes:
                            print(f"\n  ğŸ¦¸ ì˜ì›…: {hero_name}")
                            print(f"     ë³€ê²½ì‚¬í•­ {len(changes)}ê°œ:")
                            for i, change in enumerate(changes[:3], 1):
                                # ë²„í”„/ë„ˆí”„ íŒë‹¨
                                change_type = "ğŸ“ˆ BUFF" if "increased" in change.lower() else \
                                             "ğŸ“‰ NERF" if "reduced" in change.lower() or "decreased" in change.lower() else \
                                             "ğŸ”§ ADJUSTMENT"
                                
                                # ìˆ˜ì¹˜ ì¶”ì¶œ
                                value_match = re.search(r'from\s+(\d+\.?\d*)\s+to\s+(\d+\.?\d*)', change)
                                if value_match:
                                    prev_val = value_match.group(1)
                                    new_val = value_match.group(2)
                                    print(f"       {i}. {change_type} {change[:80]}...")
                                    print(f"          ({prev_val} â†’ {new_val})")
                                else:
                                    print(f"       {i}. {change_type} {change[:80]}...")
                    
                    next_element = next_element.find_next_sibling()
                
                patches.append({
                    'date': patch_date,
                    'heroes': heroes
                })
        
        print(f"\n{'='*60}")
        print(f"\nâœ… ì´ {len(patches)}ê°œ íŒ¨ì¹˜ ë°œê²¬")
        
        # í†µê³„
        all_heroes = []
        for patch in patches:
            all_heroes.extend(patch['heroes'])
        
        from collections import Counter
        hero_counts = Counter(all_heroes)
        
        print(f"\nğŸ“Š ì˜ì›…ë³„ ì—…ë°ì´íŠ¸ ë¹ˆë„ (Top 10):")
        for hero, count in hero_counts.most_common(10):
            print(f"   {hero}: {count}íšŒ")
        
        return patches
        
    except requests.RequestException as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
        return []

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ® Overwatch Patch Notes Scraper Test")
    print("=" * 60)
    scrape_overwatch_patches()
